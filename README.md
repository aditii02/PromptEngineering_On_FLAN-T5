# PromptEngineering_On_FLAN-T5
Prompt Engineering with LLM GOOGLE FLAN T5 Model 


Prompt engineering is the process of designing and refining prompts for language models like GPT-3 to obtain specific, desired outputs or responses. It involves carefully crafting the input text that you provide to the model to elicit the most relevant and accurate information or generate the desired content. Effective prompt engineering can significantly improve the performance and usability of these models.

Here are some steps to guide you on how to do prompt engineering:

1. Clearly Define Your Goal: Start by defining your objective. What do you want the model to do? Is it answering a question, generating content, providing code, or any other specific task? The clearer your goal, the more effective your prompt can be.
2. Understand the Model: Familiarize yourself with the model's capabilities and limitations. Know what it's good at and where it might struggle. This knowledge will help you design prompts that work effectively.
3. Write Clear and Specific Prompts:
4. Be explicit in your instructions: State your request clearly and explicitly in the prompt. 
5. Use context: Provide context or background information if necessary.  
6. Specify the format: If you want the response in a particular format (e.g., bullet points, paragraphs, code), make it clear in your prompt.  
7. Experiment and Iterate: Prompt engineering often involves experimentation. Start with a basic prompt and iterate, refining it as you observe the model's responses. Gradually make it more specific and tailored to your needs.
8. Analyze Model Responses: Carefully review the model's responses to your prompts. Are they meeting your expectations? If not, adjust your prompts accordingly. Try different approaches and evaluate the results.

Different type of prompt engineering techniques used:

1. Zero shot Inference - Provide with the instruction to the model like : Review this document or Classify this sentence
2. One shot Inference - Provide with the instruction and an example for reference to the model so that it can understand the example and generate a similar output.
3. Few Shot Inference - Provide with the instrcution with more than one example for more undertanding of the model , so that it generates similar output as a human would.
